{
  "best_global_step": 16551,
  "best_metric": 0.9403919983835117,
  "best_model_checkpoint": "C:\\Users\\ronif\\Desktop\\try NLP\\trained_models\\pairwise_seed42_baseline\\checkpoint-16551",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 16551,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.00906289650172195,
      "grad_norm": 4.424812316894531,
      "learning_rate": 1.994078907618875e-05,
      "loss": 0.7918,
      "step": 50
    },
    {
      "epoch": 0.0181257930034439,
      "grad_norm": 5.8468852043151855,
      "learning_rate": 1.988036976617727e-05,
      "loss": 0.729,
      "step": 100
    },
    {
      "epoch": 0.027188689505165852,
      "grad_norm": 4.158162593841553,
      "learning_rate": 1.9819950456165792e-05,
      "loss": 0.7586,
      "step": 150
    },
    {
      "epoch": 0.0362515860068878,
      "grad_norm": 2.717923402786255,
      "learning_rate": 1.9759531146154313e-05,
      "loss": 0.767,
      "step": 200
    },
    {
      "epoch": 0.045314482508609755,
      "grad_norm": 2.6564905643463135,
      "learning_rate": 1.9699111836142834e-05,
      "loss": 0.7031,
      "step": 250
    },
    {
      "epoch": 0.054377379010331704,
      "grad_norm": 29.513723373413086,
      "learning_rate": 1.9638692526131354e-05,
      "loss": 0.741,
      "step": 300
    },
    {
      "epoch": 0.06344027551205365,
      "grad_norm": 9.816946983337402,
      "learning_rate": 1.9578273216119875e-05,
      "loss": 0.5855,
      "step": 350
    },
    {
      "epoch": 0.0725031720137756,
      "grad_norm": 8.012972831726074,
      "learning_rate": 1.9517853906108396e-05,
      "loss": 0.5864,
      "step": 400
    },
    {
      "epoch": 0.08156606851549755,
      "grad_norm": 6.780975818634033,
      "learning_rate": 1.9457434596096913e-05,
      "loss": 0.5258,
      "step": 450
    },
    {
      "epoch": 0.09062896501721951,
      "grad_norm": 10.30167007446289,
      "learning_rate": 1.9397015286085434e-05,
      "loss": 0.5675,
      "step": 500
    },
    {
      "epoch": 0.09969186151894145,
      "grad_norm": 98.2782211303711,
      "learning_rate": 1.9336595976073955e-05,
      "loss": 0.5476,
      "step": 550
    },
    {
      "epoch": 0.10875475802066341,
      "grad_norm": 3.6314477920532227,
      "learning_rate": 1.9276176666062476e-05,
      "loss": 0.5073,
      "step": 600
    },
    {
      "epoch": 0.11781765452238535,
      "grad_norm": 65.32115173339844,
      "learning_rate": 1.9215757356050996e-05,
      "loss": 0.5065,
      "step": 650
    },
    {
      "epoch": 0.1268805510241073,
      "grad_norm": 5.975313186645508,
      "learning_rate": 1.9155338046039517e-05,
      "loss": 0.5036,
      "step": 700
    },
    {
      "epoch": 0.13594344752582926,
      "grad_norm": 1.930410623550415,
      "learning_rate": 1.9094918736028038e-05,
      "loss": 0.386,
      "step": 750
    },
    {
      "epoch": 0.1450063440275512,
      "grad_norm": 4.881521224975586,
      "learning_rate": 1.903449942601656e-05,
      "loss": 0.4615,
      "step": 800
    },
    {
      "epoch": 0.15406924052927315,
      "grad_norm": 2.8199658393859863,
      "learning_rate": 1.8974080116005076e-05,
      "loss": 0.4391,
      "step": 850
    },
    {
      "epoch": 0.1631321370309951,
      "grad_norm": 8.641888618469238,
      "learning_rate": 1.8913660805993597e-05,
      "loss": 0.4928,
      "step": 900
    },
    {
      "epoch": 0.17219503353271706,
      "grad_norm": 5.183952331542969,
      "learning_rate": 1.8853241495982117e-05,
      "loss": 0.4272,
      "step": 950
    },
    {
      "epoch": 0.18125793003443902,
      "grad_norm": 7.8746337890625,
      "learning_rate": 1.8792822185970638e-05,
      "loss": 0.4398,
      "step": 1000
    },
    {
      "epoch": 0.19032082653616095,
      "grad_norm": 1.400672435760498,
      "learning_rate": 1.873240287595916e-05,
      "loss": 0.3799,
      "step": 1050
    },
    {
      "epoch": 0.1993837230378829,
      "grad_norm": 3.732701063156128,
      "learning_rate": 1.8671983565947676e-05,
      "loss": 0.3721,
      "step": 1100
    },
    {
      "epoch": 0.20844661953960486,
      "grad_norm": 11.519362449645996,
      "learning_rate": 1.8611564255936197e-05,
      "loss": 0.486,
      "step": 1150
    },
    {
      "epoch": 0.21750951604132682,
      "grad_norm": 23.10849952697754,
      "learning_rate": 1.855114494592472e-05,
      "loss": 0.4479,
      "step": 1200
    },
    {
      "epoch": 0.22657241254304875,
      "grad_norm": 74.52301788330078,
      "learning_rate": 1.8490725635913242e-05,
      "loss": 0.417,
      "step": 1250
    },
    {
      "epoch": 0.2356353090447707,
      "grad_norm": 24.37240982055664,
      "learning_rate": 1.843030632590176e-05,
      "loss": 0.3559,
      "step": 1300
    },
    {
      "epoch": 0.24469820554649266,
      "grad_norm": 2.761296272277832,
      "learning_rate": 1.836988701589028e-05,
      "loss": 0.4423,
      "step": 1350
    },
    {
      "epoch": 0.2537611020482146,
      "grad_norm": 9.081701278686523,
      "learning_rate": 1.83094677058788e-05,
      "loss": 0.4374,
      "step": 1400
    },
    {
      "epoch": 0.26282399854993654,
      "grad_norm": 1.0443923473358154,
      "learning_rate": 1.824904839586732e-05,
      "loss": 0.3789,
      "step": 1450
    },
    {
      "epoch": 0.27188689505165853,
      "grad_norm": 6.639312744140625,
      "learning_rate": 1.818862908585584e-05,
      "loss": 0.4048,
      "step": 1500
    },
    {
      "epoch": 0.28094979155338046,
      "grad_norm": 12.193403244018555,
      "learning_rate": 1.812820977584436e-05,
      "loss": 0.3852,
      "step": 1550
    },
    {
      "epoch": 0.2900126880551024,
      "grad_norm": 3.996114730834961,
      "learning_rate": 1.806779046583288e-05,
      "loss": 0.4246,
      "step": 1600
    },
    {
      "epoch": 0.29907558455682437,
      "grad_norm": 14.372170448303223,
      "learning_rate": 1.80073711558214e-05,
      "loss": 0.3677,
      "step": 1650
    },
    {
      "epoch": 0.3081384810585463,
      "grad_norm": 88.56562042236328,
      "learning_rate": 1.7946951845809922e-05,
      "loss": 0.3985,
      "step": 1700
    },
    {
      "epoch": 0.3172013775602683,
      "grad_norm": 20.232236862182617,
      "learning_rate": 1.7886532535798443e-05,
      "loss": 0.4059,
      "step": 1750
    },
    {
      "epoch": 0.3262642740619902,
      "grad_norm": 11.792632102966309,
      "learning_rate": 1.7826113225786963e-05,
      "loss": 0.4438,
      "step": 1800
    },
    {
      "epoch": 0.33532717056371214,
      "grad_norm": 4.467531204223633,
      "learning_rate": 1.7765693915775484e-05,
      "loss": 0.3119,
      "step": 1850
    },
    {
      "epoch": 0.3443900670654341,
      "grad_norm": 6.5901055335998535,
      "learning_rate": 1.7705274605764005e-05,
      "loss": 0.3872,
      "step": 1900
    },
    {
      "epoch": 0.35345296356715605,
      "grad_norm": 0.6418811082839966,
      "learning_rate": 1.7644855295752522e-05,
      "loss": 0.327,
      "step": 1950
    },
    {
      "epoch": 0.36251586006887804,
      "grad_norm": 19.847030639648438,
      "learning_rate": 1.7584435985741043e-05,
      "loss": 0.4101,
      "step": 2000
    },
    {
      "epoch": 0.37157875657059997,
      "grad_norm": 15.043854713439941,
      "learning_rate": 1.7524016675729564e-05,
      "loss": 0.3075,
      "step": 2050
    },
    {
      "epoch": 0.3806416530723219,
      "grad_norm": 1.0983623266220093,
      "learning_rate": 1.7463597365718085e-05,
      "loss": 0.3847,
      "step": 2100
    },
    {
      "epoch": 0.3897045495740439,
      "grad_norm": 15.725666046142578,
      "learning_rate": 1.7403178055706605e-05,
      "loss": 0.3144,
      "step": 2150
    },
    {
      "epoch": 0.3987674460757658,
      "grad_norm": 9.389280319213867,
      "learning_rate": 1.7342758745695126e-05,
      "loss": 0.329,
      "step": 2200
    },
    {
      "epoch": 0.4078303425774878,
      "grad_norm": 14.605729103088379,
      "learning_rate": 1.7282339435683647e-05,
      "loss": 0.3697,
      "step": 2250
    },
    {
      "epoch": 0.4168932390792097,
      "grad_norm": 82.72085571289062,
      "learning_rate": 1.7221920125672168e-05,
      "loss": 0.2911,
      "step": 2300
    },
    {
      "epoch": 0.42595613558093165,
      "grad_norm": 1.6010572910308838,
      "learning_rate": 1.7161500815660685e-05,
      "loss": 0.3497,
      "step": 2350
    },
    {
      "epoch": 0.43501903208265363,
      "grad_norm": 0.5240756869316101,
      "learning_rate": 1.7101081505649206e-05,
      "loss": 0.3592,
      "step": 2400
    },
    {
      "epoch": 0.44408192858437556,
      "grad_norm": 11.602812767028809,
      "learning_rate": 1.7040662195637726e-05,
      "loss": 0.3883,
      "step": 2450
    },
    {
      "epoch": 0.4531448250860975,
      "grad_norm": 12.014883041381836,
      "learning_rate": 1.6980242885626247e-05,
      "loss": 0.3707,
      "step": 2500
    },
    {
      "epoch": 0.4622077215878195,
      "grad_norm": 65.90461730957031,
      "learning_rate": 1.6919823575614768e-05,
      "loss": 0.4339,
      "step": 2550
    },
    {
      "epoch": 0.4712706180895414,
      "grad_norm": 4.280974388122559,
      "learning_rate": 1.685940426560329e-05,
      "loss": 0.4068,
      "step": 2600
    },
    {
      "epoch": 0.4803335145912634,
      "grad_norm": 7.117880821228027,
      "learning_rate": 1.679898495559181e-05,
      "loss": 0.3536,
      "step": 2650
    },
    {
      "epoch": 0.4893964110929853,
      "grad_norm": 33.46448516845703,
      "learning_rate": 1.673856564558033e-05,
      "loss": 0.3146,
      "step": 2700
    },
    {
      "epoch": 0.49845930759470725,
      "grad_norm": 8.303694725036621,
      "learning_rate": 1.667814633556885e-05,
      "loss": 0.2853,
      "step": 2750
    },
    {
      "epoch": 0.5075222040964292,
      "grad_norm": 18.265893936157227,
      "learning_rate": 1.6617727025557368e-05,
      "loss": 0.3403,
      "step": 2800
    },
    {
      "epoch": 0.5165851005981512,
      "grad_norm": 32.10123062133789,
      "learning_rate": 1.655730771554589e-05,
      "loss": 0.3214,
      "step": 2850
    },
    {
      "epoch": 0.5256479970998731,
      "grad_norm": 3.56925106048584,
      "learning_rate": 1.649688840553441e-05,
      "loss": 0.3803,
      "step": 2900
    },
    {
      "epoch": 0.5347108936015951,
      "grad_norm": 34.80040740966797,
      "learning_rate": 1.643646909552293e-05,
      "loss": 0.4385,
      "step": 2950
    },
    {
      "epoch": 0.5437737901033171,
      "grad_norm": 0.208624467253685,
      "learning_rate": 1.637604978551145e-05,
      "loss": 0.2772,
      "step": 3000
    },
    {
      "epoch": 0.5528366866050389,
      "grad_norm": 5.358590602874756,
      "learning_rate": 1.6315630475499972e-05,
      "loss": 0.2728,
      "step": 3050
    },
    {
      "epoch": 0.5618995831067609,
      "grad_norm": 54.55867385864258,
      "learning_rate": 1.6255211165488493e-05,
      "loss": 0.3612,
      "step": 3100
    },
    {
      "epoch": 0.5709624796084829,
      "grad_norm": 86.90950012207031,
      "learning_rate": 1.6194791855477014e-05,
      "loss": 0.3192,
      "step": 3150
    },
    {
      "epoch": 0.5800253761102048,
      "grad_norm": 41.77263641357422,
      "learning_rate": 1.6134372545465534e-05,
      "loss": 0.3061,
      "step": 3200
    },
    {
      "epoch": 0.5890882726119268,
      "grad_norm": 2.989156723022461,
      "learning_rate": 1.607395323545405e-05,
      "loss": 0.3362,
      "step": 3250
    },
    {
      "epoch": 0.5981511691136487,
      "grad_norm": 10.017613410949707,
      "learning_rate": 1.6013533925442572e-05,
      "loss": 0.3311,
      "step": 3300
    },
    {
      "epoch": 0.6072140656153707,
      "grad_norm": 29.868860244750977,
      "learning_rate": 1.5953114615431093e-05,
      "loss": 0.2308,
      "step": 3350
    },
    {
      "epoch": 0.6162769621170926,
      "grad_norm": 14.019309997558594,
      "learning_rate": 1.5892695305419614e-05,
      "loss": 0.3462,
      "step": 3400
    },
    {
      "epoch": 0.6253398586188146,
      "grad_norm": 4.835094451904297,
      "learning_rate": 1.583227599540813e-05,
      "loss": 0.3164,
      "step": 3450
    },
    {
      "epoch": 0.6344027551205366,
      "grad_norm": 0.19275811314582825,
      "learning_rate": 1.5771856685396655e-05,
      "loss": 0.2568,
      "step": 3500
    },
    {
      "epoch": 0.6434656516222584,
      "grad_norm": 0.5964383482933044,
      "learning_rate": 1.5711437375385176e-05,
      "loss": 0.2486,
      "step": 3550
    },
    {
      "epoch": 0.6525285481239804,
      "grad_norm": 18.3603515625,
      "learning_rate": 1.5651018065373697e-05,
      "loss": 0.3125,
      "step": 3600
    },
    {
      "epoch": 0.6615914446257024,
      "grad_norm": 5.162291526794434,
      "learning_rate": 1.5590598755362214e-05,
      "loss": 0.301,
      "step": 3650
    },
    {
      "epoch": 0.6706543411274243,
      "grad_norm": 0.7547300457954407,
      "learning_rate": 1.5530179445350735e-05,
      "loss": 0.3826,
      "step": 3700
    },
    {
      "epoch": 0.6797172376291463,
      "grad_norm": 0.13396815955638885,
      "learning_rate": 1.5469760135339256e-05,
      "loss": 0.2693,
      "step": 3750
    },
    {
      "epoch": 0.6887801341308682,
      "grad_norm": 9.692255973815918,
      "learning_rate": 1.5409340825327777e-05,
      "loss": 0.2853,
      "step": 3800
    },
    {
      "epoch": 0.6978430306325901,
      "grad_norm": 4.726382255554199,
      "learning_rate": 1.5348921515316297e-05,
      "loss": 0.2492,
      "step": 3850
    },
    {
      "epoch": 0.7069059271343121,
      "grad_norm": 0.7802794575691223,
      "learning_rate": 1.5288502205304815e-05,
      "loss": 0.3021,
      "step": 3900
    },
    {
      "epoch": 0.7159688236360341,
      "grad_norm": 22.922630310058594,
      "learning_rate": 1.5228082895293337e-05,
      "loss": 0.3093,
      "step": 3950
    },
    {
      "epoch": 0.7250317201377561,
      "grad_norm": 0.5785248875617981,
      "learning_rate": 1.5167663585281858e-05,
      "loss": 0.2993,
      "step": 4000
    },
    {
      "epoch": 0.734094616639478,
      "grad_norm": 0.8998437523841858,
      "learning_rate": 1.5107244275270379e-05,
      "loss": 0.3078,
      "step": 4050
    },
    {
      "epoch": 0.7431575131411999,
      "grad_norm": 31.885385513305664,
      "learning_rate": 1.5046824965258898e-05,
      "loss": 0.2983,
      "step": 4100
    },
    {
      "epoch": 0.7522204096429219,
      "grad_norm": 28.024330139160156,
      "learning_rate": 1.4986405655247418e-05,
      "loss": 0.2551,
      "step": 4150
    },
    {
      "epoch": 0.7612833061446438,
      "grad_norm": 0.04668925702571869,
      "learning_rate": 1.4925986345235939e-05,
      "loss": 0.2525,
      "step": 4200
    },
    {
      "epoch": 0.7703462026463658,
      "grad_norm": 0.6662795543670654,
      "learning_rate": 1.486556703522446e-05,
      "loss": 0.2096,
      "step": 4250
    },
    {
      "epoch": 0.7794090991480878,
      "grad_norm": 0.34903889894485474,
      "learning_rate": 1.4805147725212979e-05,
      "loss": 0.2214,
      "step": 4300
    },
    {
      "epoch": 0.7884719956498096,
      "grad_norm": 0.4366128444671631,
      "learning_rate": 1.47447284152015e-05,
      "loss": 0.4129,
      "step": 4350
    },
    {
      "epoch": 0.7975348921515316,
      "grad_norm": 64.04158782958984,
      "learning_rate": 1.468430910519002e-05,
      "loss": 0.2502,
      "step": 4400
    },
    {
      "epoch": 0.8065977886532536,
      "grad_norm": 14.556272506713867,
      "learning_rate": 1.4623889795178541e-05,
      "loss": 0.2106,
      "step": 4450
    },
    {
      "epoch": 0.8156606851549756,
      "grad_norm": 4.820104122161865,
      "learning_rate": 1.4563470485167062e-05,
      "loss": 0.2537,
      "step": 4500
    },
    {
      "epoch": 0.8247235816566975,
      "grad_norm": 38.2271842956543,
      "learning_rate": 1.4503051175155581e-05,
      "loss": 0.2855,
      "step": 4550
    },
    {
      "epoch": 0.8337864781584194,
      "grad_norm": 135.40171813964844,
      "learning_rate": 1.4442631865144102e-05,
      "loss": 0.2889,
      "step": 4600
    },
    {
      "epoch": 0.8428493746601414,
      "grad_norm": 22.30186653137207,
      "learning_rate": 1.4382212555132623e-05,
      "loss": 0.3166,
      "step": 4650
    },
    {
      "epoch": 0.8519122711618633,
      "grad_norm": 0.4609757661819458,
      "learning_rate": 1.4321793245121143e-05,
      "loss": 0.1756,
      "step": 4700
    },
    {
      "epoch": 0.8609751676635853,
      "grad_norm": 0.8545189499855042,
      "learning_rate": 1.426137393510966e-05,
      "loss": 0.2514,
      "step": 4750
    },
    {
      "epoch": 0.8700380641653073,
      "grad_norm": 4.633280277252197,
      "learning_rate": 1.4200954625098181e-05,
      "loss": 0.2033,
      "step": 4800
    },
    {
      "epoch": 0.8791009606670291,
      "grad_norm": 24.18552589416504,
      "learning_rate": 1.4140535315086704e-05,
      "loss": 0.3573,
      "step": 4850
    },
    {
      "epoch": 0.8881638571687511,
      "grad_norm": 24.087385177612305,
      "learning_rate": 1.4080116005075225e-05,
      "loss": 0.249,
      "step": 4900
    },
    {
      "epoch": 0.8972267536704731,
      "grad_norm": 5.150639533996582,
      "learning_rate": 1.4019696695063742e-05,
      "loss": 0.2145,
      "step": 4950
    },
    {
      "epoch": 0.906289650172195,
      "grad_norm": 3.8027729988098145,
      "learning_rate": 1.3959277385052263e-05,
      "loss": 0.283,
      "step": 5000
    },
    {
      "epoch": 0.915352546673917,
      "grad_norm": 0.05889660865068436,
      "learning_rate": 1.3898858075040783e-05,
      "loss": 0.2537,
      "step": 5050
    },
    {
      "epoch": 0.924415443175639,
      "grad_norm": 3.708282470703125,
      "learning_rate": 1.3838438765029304e-05,
      "loss": 0.2904,
      "step": 5100
    },
    {
      "epoch": 0.9334783396773609,
      "grad_norm": 0.18010425567626953,
      "learning_rate": 1.3778019455017827e-05,
      "loss": 0.2344,
      "step": 5150
    },
    {
      "epoch": 0.9425412361790828,
      "grad_norm": 0.07651583850383759,
      "learning_rate": 1.3717600145006344e-05,
      "loss": 0.3234,
      "step": 5200
    },
    {
      "epoch": 0.9516041326808048,
      "grad_norm": 6.2569661140441895,
      "learning_rate": 1.3657180834994865e-05,
      "loss": 0.2286,
      "step": 5250
    },
    {
      "epoch": 0.9606670291825268,
      "grad_norm": 26.484317779541016,
      "learning_rate": 1.3596761524983386e-05,
      "loss": 0.29,
      "step": 5300
    },
    {
      "epoch": 0.9697299256842487,
      "grad_norm": 0.16976644098758698,
      "learning_rate": 1.3536342214971906e-05,
      "loss": 0.2182,
      "step": 5350
    },
    {
      "epoch": 0.9787928221859706,
      "grad_norm": 194.3174285888672,
      "learning_rate": 1.3475922904960425e-05,
      "loss": 0.2545,
      "step": 5400
    },
    {
      "epoch": 0.9878557186876926,
      "grad_norm": 0.13845597207546234,
      "learning_rate": 1.3415503594948946e-05,
      "loss": 0.2529,
      "step": 5450
    },
    {
      "epoch": 0.9969186151894145,
      "grad_norm": 0.061671629548072815,
      "learning_rate": 1.3355084284937467e-05,
      "loss": 0.2164,
      "step": 5500
    },
    {
      "epoch": 1.0,
      "eval_acc_3class": 0.9437030859049208,
      "eval_any_f1": 0.8903007200338839,
      "eval_any_precision": 0.9044750430292599,
      "eval_any_recall": 0.8765638031693077,
      "eval_cm00": 6972,
      "eval_cm01": 216,
      "eval_cm02": 6,
      "eval_cm10": 287,
      "eval_cm11": 1476,
      "eval_cm12": 18,
      "eval_cm20": 9,
      "eval_cm21": 4,
      "eval_cm22": 604,
      "eval_loss": 0.24010764062404633,
      "eval_runtime": 13.9621,
      "eval_samples_per_second": 687.005,
      "eval_steps_per_second": 42.974,
      "eval_type_f1": 0.9821138211382114,
      "eval_type_precision": 0.9710610932475884,
      "eval_type_recall": 0.993421052631579,
      "eval_type_support": 2102.0,
      "step": 5517
    },
    {
      "epoch": 1.0059815116911366,
      "grad_norm": 0.16590352356433868,
      "learning_rate": 1.3294664974925988e-05,
      "loss": 0.2094,
      "step": 5550
    },
    {
      "epoch": 1.0150444081928585,
      "grad_norm": 0.23416003584861755,
      "learning_rate": 1.3234245664914507e-05,
      "loss": 0.2135,
      "step": 5600
    },
    {
      "epoch": 1.0241073046945803,
      "grad_norm": 17.074384689331055,
      "learning_rate": 1.3173826354903027e-05,
      "loss": 0.2462,
      "step": 5650
    },
    {
      "epoch": 1.0331702011963024,
      "grad_norm": 62.528926849365234,
      "learning_rate": 1.3113407044891548e-05,
      "loss": 0.2218,
      "step": 5700
    },
    {
      "epoch": 1.0422330976980243,
      "grad_norm": 0.3799905478954315,
      "learning_rate": 1.3052987734880069e-05,
      "loss": 0.2578,
      "step": 5750
    },
    {
      "epoch": 1.0512959941997462,
      "grad_norm": 28.65998649597168,
      "learning_rate": 1.299256842486859e-05,
      "loss": 0.2623,
      "step": 5800
    },
    {
      "epoch": 1.0603588907014683,
      "grad_norm": 0.178532212972641,
      "learning_rate": 1.2932149114857109e-05,
      "loss": 0.3432,
      "step": 5850
    },
    {
      "epoch": 1.0694217872031901,
      "grad_norm": 24.606853485107422,
      "learning_rate": 1.287172980484563e-05,
      "loss": 0.247,
      "step": 5900
    },
    {
      "epoch": 1.078484683704912,
      "grad_norm": 0.1088397353887558,
      "learning_rate": 1.281131049483415e-05,
      "loss": 0.1995,
      "step": 5950
    },
    {
      "epoch": 1.0875475802066341,
      "grad_norm": 14.046685218811035,
      "learning_rate": 1.2750891184822671e-05,
      "loss": 0.2337,
      "step": 6000
    },
    {
      "epoch": 1.096610476708356,
      "grad_norm": 0.08899282664060593,
      "learning_rate": 1.269047187481119e-05,
      "loss": 0.2196,
      "step": 6050
    },
    {
      "epoch": 1.1056733732100779,
      "grad_norm": 30.255260467529297,
      "learning_rate": 1.263005256479971e-05,
      "loss": 0.2522,
      "step": 6100
    },
    {
      "epoch": 1.1147362697118,
      "grad_norm": 33.32568359375,
      "learning_rate": 1.2569633254788232e-05,
      "loss": 0.1942,
      "step": 6150
    },
    {
      "epoch": 1.1237991662135218,
      "grad_norm": 0.5867761969566345,
      "learning_rate": 1.2509213944776752e-05,
      "loss": 0.2659,
      "step": 6200
    },
    {
      "epoch": 1.1328620627152437,
      "grad_norm": 0.029118360951542854,
      "learning_rate": 1.2448794634765271e-05,
      "loss": 0.1396,
      "step": 6250
    },
    {
      "epoch": 1.1419249592169658,
      "grad_norm": 0.6458585262298584,
      "learning_rate": 1.2388375324753792e-05,
      "loss": 0.1893,
      "step": 6300
    },
    {
      "epoch": 1.1509878557186877,
      "grad_norm": 3.8859498500823975,
      "learning_rate": 1.2327956014742313e-05,
      "loss": 0.2662,
      "step": 6350
    },
    {
      "epoch": 1.1600507522204095,
      "grad_norm": 3.5862412452697754,
      "learning_rate": 1.2267536704730834e-05,
      "loss": 0.2015,
      "step": 6400
    },
    {
      "epoch": 1.1691136487221316,
      "grad_norm": 14.95142650604248,
      "learning_rate": 1.2207117394719353e-05,
      "loss": 0.2274,
      "step": 6450
    },
    {
      "epoch": 1.1781765452238535,
      "grad_norm": 0.19085632264614105,
      "learning_rate": 1.2146698084707873e-05,
      "loss": 0.2311,
      "step": 6500
    },
    {
      "epoch": 1.1872394417255756,
      "grad_norm": 0.27042895555496216,
      "learning_rate": 1.2086278774696394e-05,
      "loss": 0.2005,
      "step": 6550
    },
    {
      "epoch": 1.1963023382272975,
      "grad_norm": 0.5955772995948792,
      "learning_rate": 1.2025859464684915e-05,
      "loss": 0.2214,
      "step": 6600
    },
    {
      "epoch": 1.2053652347290194,
      "grad_norm": 0.2554798722267151,
      "learning_rate": 1.1965440154673436e-05,
      "loss": 0.2153,
      "step": 6650
    },
    {
      "epoch": 1.2144281312307412,
      "grad_norm": 0.24287326633930206,
      "learning_rate": 1.1905020844661955e-05,
      "loss": 0.1743,
      "step": 6700
    },
    {
      "epoch": 1.2234910277324633,
      "grad_norm": 4.390665531158447,
      "learning_rate": 1.1844601534650475e-05,
      "loss": 0.2152,
      "step": 6750
    },
    {
      "epoch": 1.2325539242341852,
      "grad_norm": 34.745933532714844,
      "learning_rate": 1.1784182224638996e-05,
      "loss": 0.193,
      "step": 6800
    },
    {
      "epoch": 1.2416168207359073,
      "grad_norm": 0.1920711249113083,
      "learning_rate": 1.1723762914627517e-05,
      "loss": 0.2319,
      "step": 6850
    },
    {
      "epoch": 1.2506797172376292,
      "grad_norm": 65.76387023925781,
      "learning_rate": 1.1663343604616036e-05,
      "loss": 0.225,
      "step": 6900
    },
    {
      "epoch": 1.259742613739351,
      "grad_norm": 0.3748055696487427,
      "learning_rate": 1.1602924294604557e-05,
      "loss": 0.2137,
      "step": 6950
    },
    {
      "epoch": 1.268805510241073,
      "grad_norm": 90.51434326171875,
      "learning_rate": 1.1542504984593078e-05,
      "loss": 0.19,
      "step": 7000
    },
    {
      "epoch": 1.277868406742795,
      "grad_norm": 0.7115565538406372,
      "learning_rate": 1.1482085674581598e-05,
      "loss": 0.2234,
      "step": 7050
    },
    {
      "epoch": 1.2869313032445169,
      "grad_norm": 1.8377584218978882,
      "learning_rate": 1.1421666364570116e-05,
      "loss": 0.2329,
      "step": 7100
    },
    {
      "epoch": 1.295994199746239,
      "grad_norm": 0.24522189795970917,
      "learning_rate": 1.1361247054558638e-05,
      "loss": 0.185,
      "step": 7150
    },
    {
      "epoch": 1.3050570962479608,
      "grad_norm": 0.27286529541015625,
      "learning_rate": 1.1300827744547159e-05,
      "loss": 0.215,
      "step": 7200
    },
    {
      "epoch": 1.3141199927496827,
      "grad_norm": 138.1607666015625,
      "learning_rate": 1.124040843453568e-05,
      "loss": 0.2571,
      "step": 7250
    },
    {
      "epoch": 1.3231828892514048,
      "grad_norm": 0.05802833288908005,
      "learning_rate": 1.11799891245242e-05,
      "loss": 0.2253,
      "step": 7300
    },
    {
      "epoch": 1.3322457857531267,
      "grad_norm": 9.148231506347656,
      "learning_rate": 1.1119569814512718e-05,
      "loss": 0.1279,
      "step": 7350
    },
    {
      "epoch": 1.3413086822548488,
      "grad_norm": 5.017509460449219,
      "learning_rate": 1.1059150504501238e-05,
      "loss": 0.2221,
      "step": 7400
    },
    {
      "epoch": 1.3503715787565707,
      "grad_norm": 0.09168949723243713,
      "learning_rate": 1.0998731194489761e-05,
      "loss": 0.2645,
      "step": 7450
    },
    {
      "epoch": 1.3594344752582925,
      "grad_norm": 36.684226989746094,
      "learning_rate": 1.0938311884478282e-05,
      "loss": 0.2727,
      "step": 7500
    },
    {
      "epoch": 1.3684973717600144,
      "grad_norm": 0.4379967451095581,
      "learning_rate": 1.0877892574466799e-05,
      "loss": 0.1728,
      "step": 7550
    },
    {
      "epoch": 1.3775602682617365,
      "grad_norm": 0.24989868700504303,
      "learning_rate": 1.081747326445532e-05,
      "loss": 0.1687,
      "step": 7600
    },
    {
      "epoch": 1.3866231647634584,
      "grad_norm": 0.8583495020866394,
      "learning_rate": 1.075705395444384e-05,
      "loss": 0.2006,
      "step": 7650
    },
    {
      "epoch": 1.3956860612651805,
      "grad_norm": 0.3621542155742645,
      "learning_rate": 1.0696634644432361e-05,
      "loss": 0.1819,
      "step": 7700
    },
    {
      "epoch": 1.4047489577669023,
      "grad_norm": 0.08483018726110458,
      "learning_rate": 1.063621533442088e-05,
      "loss": 0.2015,
      "step": 7750
    },
    {
      "epoch": 1.4138118542686242,
      "grad_norm": 39.87971115112305,
      "learning_rate": 1.0575796024409401e-05,
      "loss": 0.22,
      "step": 7800
    },
    {
      "epoch": 1.422874750770346,
      "grad_norm": 0.170455202460289,
      "learning_rate": 1.0515376714397922e-05,
      "loss": 0.1702,
      "step": 7850
    },
    {
      "epoch": 1.4319376472720682,
      "grad_norm": 0.1717105656862259,
      "learning_rate": 1.0454957404386443e-05,
      "loss": 0.1817,
      "step": 7900
    },
    {
      "epoch": 1.44100054377379,
      "grad_norm": 17.350618362426758,
      "learning_rate": 1.0394538094374963e-05,
      "loss": 0.1315,
      "step": 7950
    },
    {
      "epoch": 1.4500634402755121,
      "grad_norm": 0.036356110125780106,
      "learning_rate": 1.0334118784363482e-05,
      "loss": 0.2214,
      "step": 8000
    },
    {
      "epoch": 1.459126336777234,
      "grad_norm": 25.72535514831543,
      "learning_rate": 1.0273699474352003e-05,
      "loss": 0.2209,
      "step": 8050
    },
    {
      "epoch": 1.468189233278956,
      "grad_norm": 0.24538554251194,
      "learning_rate": 1.0213280164340524e-05,
      "loss": 0.2047,
      "step": 8100
    },
    {
      "epoch": 1.4772521297806778,
      "grad_norm": 0.6200161576271057,
      "learning_rate": 1.0152860854329045e-05,
      "loss": 0.1881,
      "step": 8150
    },
    {
      "epoch": 1.4863150262823999,
      "grad_norm": 0.24364952743053436,
      "learning_rate": 1.0092441544317564e-05,
      "loss": 0.1535,
      "step": 8200
    },
    {
      "epoch": 1.4953779227841217,
      "grad_norm": 89.4508056640625,
      "learning_rate": 1.0032022234306084e-05,
      "loss": 0.1985,
      "step": 8250
    },
    {
      "epoch": 1.5044408192858438,
      "grad_norm": 36.990089416503906,
      "learning_rate": 9.971602924294605e-06,
      "loss": 0.2111,
      "step": 8300
    },
    {
      "epoch": 1.5135037157875657,
      "grad_norm": 0.11498187482357025,
      "learning_rate": 9.911183614283126e-06,
      "loss": 0.1873,
      "step": 8350
    },
    {
      "epoch": 1.5225666122892876,
      "grad_norm": 8.482046127319336,
      "learning_rate": 9.850764304271647e-06,
      "loss": 0.1946,
      "step": 8400
    },
    {
      "epoch": 1.5316295087910095,
      "grad_norm": 22.717607498168945,
      "learning_rate": 9.790344994260166e-06,
      "loss": 0.2098,
      "step": 8450
    },
    {
      "epoch": 1.5406924052927315,
      "grad_norm": 0.3390228748321533,
      "learning_rate": 9.729925684248687e-06,
      "loss": 0.222,
      "step": 8500
    },
    {
      "epoch": 1.5497553017944536,
      "grad_norm": 0.024583039805293083,
      "learning_rate": 9.669506374237207e-06,
      "loss": 0.1192,
      "step": 8550
    },
    {
      "epoch": 1.5588181982961755,
      "grad_norm": 130.83502197265625,
      "learning_rate": 9.609087064225728e-06,
      "loss": 0.1806,
      "step": 8600
    },
    {
      "epoch": 1.5678810947978974,
      "grad_norm": 0.15764173865318298,
      "learning_rate": 9.548667754214249e-06,
      "loss": 0.1748,
      "step": 8650
    },
    {
      "epoch": 1.5769439912996193,
      "grad_norm": 8.201068878173828,
      "learning_rate": 9.488248444202768e-06,
      "loss": 0.2321,
      "step": 8700
    },
    {
      "epoch": 1.5860068878013414,
      "grad_norm": 0.09651259332895279,
      "learning_rate": 9.427829134191289e-06,
      "loss": 0.2308,
      "step": 8750
    },
    {
      "epoch": 1.5950697843030632,
      "grad_norm": 0.6789698600769043,
      "learning_rate": 9.367409824179808e-06,
      "loss": 0.2184,
      "step": 8800
    },
    {
      "epoch": 1.6041326808047853,
      "grad_norm": 0.040137384086847305,
      "learning_rate": 9.306990514168328e-06,
      "loss": 0.1503,
      "step": 8850
    },
    {
      "epoch": 1.6131955773065072,
      "grad_norm": 0.06351740658283234,
      "learning_rate": 9.24657120415685e-06,
      "loss": 0.1167,
      "step": 8900
    },
    {
      "epoch": 1.622258473808229,
      "grad_norm": 0.29454442858695984,
      "learning_rate": 9.18615189414537e-06,
      "loss": 0.0725,
      "step": 8950
    },
    {
      "epoch": 1.631321370309951,
      "grad_norm": 1.6389204263687134,
      "learning_rate": 9.125732584133889e-06,
      "loss": 0.1938,
      "step": 9000
    },
    {
      "epoch": 1.640384266811673,
      "grad_norm": 0.12683461606502533,
      "learning_rate": 9.06531327412241e-06,
      "loss": 0.1378,
      "step": 9050
    },
    {
      "epoch": 1.649447163313395,
      "grad_norm": 0.0414201021194458,
      "learning_rate": 9.00489396411093e-06,
      "loss": 0.1807,
      "step": 9100
    },
    {
      "epoch": 1.658510059815117,
      "grad_norm": 0.8170661926269531,
      "learning_rate": 8.944474654099451e-06,
      "loss": 0.2027,
      "step": 9150
    },
    {
      "epoch": 1.6675729563168389,
      "grad_norm": 182.5217742919922,
      "learning_rate": 8.884055344087972e-06,
      "loss": 0.177,
      "step": 9200
    },
    {
      "epoch": 1.6766358528185608,
      "grad_norm": 0.07373789697885513,
      "learning_rate": 8.823636034076491e-06,
      "loss": 0.207,
      "step": 9250
    },
    {
      "epoch": 1.6856987493202826,
      "grad_norm": 3.4156415462493896,
      "learning_rate": 8.763216724065012e-06,
      "loss": 0.2602,
      "step": 9300
    },
    {
      "epoch": 1.6947616458220047,
      "grad_norm": 22.7696533203125,
      "learning_rate": 8.702797414053533e-06,
      "loss": 0.1897,
      "step": 9350
    },
    {
      "epoch": 1.7038245423237268,
      "grad_norm": 0.04821137711405754,
      "learning_rate": 8.642378104042053e-06,
      "loss": 0.2241,
      "step": 9400
    },
    {
      "epoch": 1.7128874388254487,
      "grad_norm": 0.045037902891635895,
      "learning_rate": 8.581958794030572e-06,
      "loss": 0.1435,
      "step": 9450
    },
    {
      "epoch": 1.7219503353271706,
      "grad_norm": 0.39160263538360596,
      "learning_rate": 8.521539484019093e-06,
      "loss": 0.1689,
      "step": 9500
    },
    {
      "epoch": 1.7310132318288924,
      "grad_norm": 0.07891237735748291,
      "learning_rate": 8.461120174007614e-06,
      "loss": 0.1971,
      "step": 9550
    },
    {
      "epoch": 1.7400761283306143,
      "grad_norm": 1.818062663078308,
      "learning_rate": 8.400700863996135e-06,
      "loss": 0.2,
      "step": 9600
    },
    {
      "epoch": 1.7491390248323364,
      "grad_norm": 0.12438338994979858,
      "learning_rate": 8.340281553984654e-06,
      "loss": 0.124,
      "step": 9650
    },
    {
      "epoch": 1.7582019213340585,
      "grad_norm": 17.152441024780273,
      "learning_rate": 8.279862243973174e-06,
      "loss": 0.2143,
      "step": 9700
    },
    {
      "epoch": 1.7672648178357804,
      "grad_norm": 8.839557647705078,
      "learning_rate": 8.219442933961695e-06,
      "loss": 0.1971,
      "step": 9750
    },
    {
      "epoch": 1.7763277143375023,
      "grad_norm": 6.765636444091797,
      "learning_rate": 8.159023623950216e-06,
      "loss": 0.1514,
      "step": 9800
    },
    {
      "epoch": 1.7853906108392241,
      "grad_norm": 0.01620176061987877,
      "learning_rate": 8.098604313938737e-06,
      "loss": 0.07,
      "step": 9850
    },
    {
      "epoch": 1.7944535073409462,
      "grad_norm": 0.16888545453548431,
      "learning_rate": 8.038185003927256e-06,
      "loss": 0.1412,
      "step": 9900
    },
    {
      "epoch": 1.803516403842668,
      "grad_norm": 9.876944541931152,
      "learning_rate": 7.977765693915776e-06,
      "loss": 0.2791,
      "step": 9950
    },
    {
      "epoch": 1.8125793003443902,
      "grad_norm": 24.682504653930664,
      "learning_rate": 7.917346383904296e-06,
      "loss": 0.2281,
      "step": 10000
    },
    {
      "epoch": 1.821642196846112,
      "grad_norm": 35.04514694213867,
      "learning_rate": 7.856927073892818e-06,
      "loss": 0.2553,
      "step": 10050
    },
    {
      "epoch": 1.830705093347834,
      "grad_norm": 5.981524467468262,
      "learning_rate": 7.796507763881337e-06,
      "loss": 0.1645,
      "step": 10100
    },
    {
      "epoch": 1.8397679898495558,
      "grad_norm": 0.05826414003968239,
      "learning_rate": 7.736088453869858e-06,
      "loss": 0.1569,
      "step": 10150
    },
    {
      "epoch": 1.848830886351278,
      "grad_norm": 1.2458908557891846,
      "learning_rate": 7.675669143858377e-06,
      "loss": 0.1442,
      "step": 10200
    },
    {
      "epoch": 1.8578937828529998,
      "grad_norm": 0.05757084861397743,
      "learning_rate": 7.6152498338468985e-06,
      "loss": 0.1379,
      "step": 10250
    },
    {
      "epoch": 1.8669566793547219,
      "grad_norm": 115.1375732421875,
      "learning_rate": 7.554830523835418e-06,
      "loss": 0.1367,
      "step": 10300
    },
    {
      "epoch": 1.8760195758564437,
      "grad_norm": 0.21485856175422668,
      "learning_rate": 7.494411213823939e-06,
      "loss": 0.1358,
      "step": 10350
    },
    {
      "epoch": 1.8850824723581656,
      "grad_norm": 0.9435495138168335,
      "learning_rate": 7.433991903812459e-06,
      "loss": 0.1193,
      "step": 10400
    },
    {
      "epoch": 1.8941453688598875,
      "grad_norm": 1.1100834608078003,
      "learning_rate": 7.37357259380098e-06,
      "loss": 0.1918,
      "step": 10450
    },
    {
      "epoch": 1.9032082653616096,
      "grad_norm": 12.271430015563965,
      "learning_rate": 7.313153283789499e-06,
      "loss": 0.1619,
      "step": 10500
    },
    {
      "epoch": 1.9122711618633317,
      "grad_norm": 26.940645217895508,
      "learning_rate": 7.2527339737780204e-06,
      "loss": 0.2099,
      "step": 10550
    },
    {
      "epoch": 1.9213340583650536,
      "grad_norm": 7.453347206115723,
      "learning_rate": 7.192314663766541e-06,
      "loss": 0.1459,
      "step": 10600
    },
    {
      "epoch": 1.9303969548667754,
      "grad_norm": 0.23182061314582825,
      "learning_rate": 7.13189535375506e-06,
      "loss": 0.1323,
      "step": 10650
    },
    {
      "epoch": 1.9394598513684973,
      "grad_norm": 8.296428680419922,
      "learning_rate": 7.071476043743582e-06,
      "loss": 0.1759,
      "step": 10700
    },
    {
      "epoch": 1.9485227478702192,
      "grad_norm": 0.28779059648513794,
      "learning_rate": 7.011056733732101e-06,
      "loss": 0.0871,
      "step": 10750
    },
    {
      "epoch": 1.9575856443719413,
      "grad_norm": 0.015000212006270885,
      "learning_rate": 6.950637423720622e-06,
      "loss": 0.1813,
      "step": 10800
    },
    {
      "epoch": 1.9666485408736634,
      "grad_norm": 45.597312927246094,
      "learning_rate": 6.8902181137091416e-06,
      "loss": 0.1792,
      "step": 10850
    },
    {
      "epoch": 1.9757114373753852,
      "grad_norm": 0.3433367908000946,
      "learning_rate": 6.829798803697662e-06,
      "loss": 0.1741,
      "step": 10900
    },
    {
      "epoch": 1.984774333877107,
      "grad_norm": 16.650806427001953,
      "learning_rate": 6.769379493686182e-06,
      "loss": 0.1973,
      "step": 10950
    },
    {
      "epoch": 1.993837230378829,
      "grad_norm": 0.21331003308296204,
      "learning_rate": 6.708960183674703e-06,
      "loss": 0.1477,
      "step": 11000
    },
    {
      "epoch": 2.0,
      "eval_acc_3class": 0.9594453711426189,
      "eval_any_f1": 0.9215365753984471,
      "eval_any_precision": 0.9034455128205128,
      "eval_any_recall": 0.9403669724770642,
      "eval_cm00": 6953,
      "eval_cm01": 229,
      "eval_cm02": 12,
      "eval_cm10": 143,
      "eval_cm11": 1636,
      "eval_cm12": 2,
      "eval_cm20": 0,
      "eval_cm21": 3,
      "eval_cm22": 614,
      "eval_loss": 0.17622512578964233,
      "eval_runtime": 13.902,
      "eval_samples_per_second": 689.974,
      "eval_steps_per_second": 43.159,
      "eval_type_f1": 0.9959448499594484,
      "eval_type_precision": 0.9967532467532467,
      "eval_type_recall": 0.9951377633711507,
      "eval_type_support": 2255.0,
      "step": 11034
    },
    {
      "epoch": 2.002900126880551,
      "grad_norm": 0.2959515154361725,
      "learning_rate": 6.648540873663223e-06,
      "loss": 0.0833,
      "step": 11050
    },
    {
      "epoch": 2.011963023382273,
      "grad_norm": 1.443359613418579,
      "learning_rate": 6.588121563651744e-06,
      "loss": 0.1493,
      "step": 11100
    },
    {
      "epoch": 2.021025919883995,
      "grad_norm": 0.8473641276359558,
      "learning_rate": 6.5277022536402635e-06,
      "loss": 0.1311,
      "step": 11150
    },
    {
      "epoch": 2.030088816385717,
      "grad_norm": 105.66851806640625,
      "learning_rate": 6.467282943628784e-06,
      "loss": 0.1476,
      "step": 11200
    },
    {
      "epoch": 2.039151712887439,
      "grad_norm": 0.19966275990009308,
      "learning_rate": 6.406863633617305e-06,
      "loss": 0.1009,
      "step": 11250
    },
    {
      "epoch": 2.0482146093891607,
      "grad_norm": 0.04081737622618675,
      "learning_rate": 6.346444323605825e-06,
      "loss": 0.1148,
      "step": 11300
    },
    {
      "epoch": 2.0572775058908825,
      "grad_norm": 0.3884185254573822,
      "learning_rate": 6.286025013594346e-06,
      "loss": 0.1234,
      "step": 11350
    },
    {
      "epoch": 2.066340402392605,
      "grad_norm": 0.433207631111145,
      "learning_rate": 6.225605703582866e-06,
      "loss": 0.1821,
      "step": 11400
    },
    {
      "epoch": 2.0754032988943267,
      "grad_norm": 0.3914920687675476,
      "learning_rate": 6.165186393571386e-06,
      "loss": 0.171,
      "step": 11450
    },
    {
      "epoch": 2.0844661953960486,
      "grad_norm": 0.028292691335082054,
      "learning_rate": 6.104767083559906e-06,
      "loss": 0.1322,
      "step": 11500
    },
    {
      "epoch": 2.0935290918977705,
      "grad_norm": 0.0617426373064518,
      "learning_rate": 6.044347773548427e-06,
      "loss": 0.1108,
      "step": 11550
    },
    {
      "epoch": 2.1025919883994924,
      "grad_norm": 0.12860214710235596,
      "learning_rate": 5.983928463536947e-06,
      "loss": 0.1964,
      "step": 11600
    },
    {
      "epoch": 2.1116548849012142,
      "grad_norm": 0.3256056606769562,
      "learning_rate": 5.923509153525468e-06,
      "loss": 0.1458,
      "step": 11650
    },
    {
      "epoch": 2.1207177814029365,
      "grad_norm": 0.003814100753515959,
      "learning_rate": 5.863089843513987e-06,
      "loss": 0.137,
      "step": 11700
    },
    {
      "epoch": 2.1297806779046584,
      "grad_norm": 0.05090511217713356,
      "learning_rate": 5.802670533502508e-06,
      "loss": 0.1467,
      "step": 11750
    },
    {
      "epoch": 2.1388435744063803,
      "grad_norm": 0.12555865943431854,
      "learning_rate": 5.742251223491027e-06,
      "loss": 0.1408,
      "step": 11800
    },
    {
      "epoch": 2.147906470908102,
      "grad_norm": 63.28609085083008,
      "learning_rate": 5.681831913479548e-06,
      "loss": 0.1679,
      "step": 11850
    },
    {
      "epoch": 2.156969367409824,
      "grad_norm": 0.004831742495298386,
      "learning_rate": 5.62141260346807e-06,
      "loss": 0.1214,
      "step": 11900
    },
    {
      "epoch": 2.1660322639115464,
      "grad_norm": 0.8147190809249878,
      "learning_rate": 5.560993293456589e-06,
      "loss": 0.127,
      "step": 11950
    },
    {
      "epoch": 2.1750951604132682,
      "grad_norm": 0.02159668318927288,
      "learning_rate": 5.5005739834451095e-06,
      "loss": 0.1141,
      "step": 12000
    },
    {
      "epoch": 2.18415805691499,
      "grad_norm": 0.058899395167827606,
      "learning_rate": 5.4401546734336294e-06,
      "loss": 0.1228,
      "step": 12050
    },
    {
      "epoch": 2.193220953416712,
      "grad_norm": 29.808706283569336,
      "learning_rate": 5.37973536342215e-06,
      "loss": 0.1229,
      "step": 12100
    },
    {
      "epoch": 2.202283849918434,
      "grad_norm": 19.083721160888672,
      "learning_rate": 5.31931605341067e-06,
      "loss": 0.1209,
      "step": 12150
    },
    {
      "epoch": 2.2113467464201557,
      "grad_norm": 68.2667465209961,
      "learning_rate": 5.258896743399191e-06,
      "loss": 0.1836,
      "step": 12200
    },
    {
      "epoch": 2.220409642921878,
      "grad_norm": 0.08133260905742645,
      "learning_rate": 5.198477433387711e-06,
      "loss": 0.2309,
      "step": 12250
    },
    {
      "epoch": 2.2294725394236,
      "grad_norm": 2.4300477504730225,
      "learning_rate": 5.1380581233762315e-06,
      "loss": 0.1354,
      "step": 12300
    },
    {
      "epoch": 2.238535435925322,
      "grad_norm": 0.00490414397791028,
      "learning_rate": 5.077638813364751e-06,
      "loss": 0.1329,
      "step": 12350
    },
    {
      "epoch": 2.2475983324270437,
      "grad_norm": 4.6221699714660645,
      "learning_rate": 5.017219503353272e-06,
      "loss": 0.1592,
      "step": 12400
    },
    {
      "epoch": 2.2566612289287655,
      "grad_norm": 0.0036137180868536234,
      "learning_rate": 4.956800193341793e-06,
      "loss": 0.0699,
      "step": 12450
    },
    {
      "epoch": 2.2657241254304874,
      "grad_norm": 4.732656955718994,
      "learning_rate": 4.896380883330313e-06,
      "loss": 0.1318,
      "step": 12500
    },
    {
      "epoch": 2.2747870219322097,
      "grad_norm": 3.5610191822052,
      "learning_rate": 4.835961573318833e-06,
      "loss": 0.1398,
      "step": 12550
    },
    {
      "epoch": 2.2838499184339316,
      "grad_norm": 41.25004196166992,
      "learning_rate": 4.7755422633073535e-06,
      "loss": 0.0793,
      "step": 12600
    },
    {
      "epoch": 2.2929128149356535,
      "grad_norm": 1.190490961074829,
      "learning_rate": 4.715122953295873e-06,
      "loss": 0.1181,
      "step": 12650
    },
    {
      "epoch": 2.3019757114373753,
      "grad_norm": 0.08562813699245453,
      "learning_rate": 4.654703643284394e-06,
      "loss": 0.1057,
      "step": 12700
    },
    {
      "epoch": 2.311038607939097,
      "grad_norm": 0.07928313314914703,
      "learning_rate": 4.594284333272914e-06,
      "loss": 0.0474,
      "step": 12750
    },
    {
      "epoch": 2.320101504440819,
      "grad_norm": 10.783183097839355,
      "learning_rate": 4.533865023261435e-06,
      "loss": 0.1566,
      "step": 12800
    },
    {
      "epoch": 2.3291644009425414,
      "grad_norm": 0.0715600922703743,
      "learning_rate": 4.473445713249955e-06,
      "loss": 0.2139,
      "step": 12850
    },
    {
      "epoch": 2.3382272974442633,
      "grad_norm": 0.034533269703388214,
      "learning_rate": 4.4130264032384754e-06,
      "loss": 0.1309,
      "step": 12900
    },
    {
      "epoch": 2.347290193945985,
      "grad_norm": 0.43779340386390686,
      "learning_rate": 4.352607093226996e-06,
      "loss": 0.1555,
      "step": 12950
    },
    {
      "epoch": 2.356353090447707,
      "grad_norm": 0.04443870857357979,
      "learning_rate": 4.292187783215516e-06,
      "loss": 0.1224,
      "step": 13000
    },
    {
      "epoch": 2.365415986949429,
      "grad_norm": 90.34928894042969,
      "learning_rate": 4.231768473204037e-06,
      "loss": 0.19,
      "step": 13050
    },
    {
      "epoch": 2.374478883451151,
      "grad_norm": 0.041819021105766296,
      "learning_rate": 4.171349163192557e-06,
      "loss": 0.0957,
      "step": 13100
    },
    {
      "epoch": 2.383541779952873,
      "grad_norm": 0.5109889507293701,
      "learning_rate": 4.110929853181077e-06,
      "loss": 0.186,
      "step": 13150
    },
    {
      "epoch": 2.392604676454595,
      "grad_norm": 37.900535583496094,
      "learning_rate": 4.050510543169597e-06,
      "loss": 0.1699,
      "step": 13200
    },
    {
      "epoch": 2.401667572956317,
      "grad_norm": 0.06766591966152191,
      "learning_rate": 3.990091233158117e-06,
      "loss": 0.1553,
      "step": 13250
    },
    {
      "epoch": 2.4107304694580387,
      "grad_norm": 0.1304604858160019,
      "learning_rate": 3.929671923146638e-06,
      "loss": 0.1551,
      "step": 13300
    },
    {
      "epoch": 2.4197933659597606,
      "grad_norm": 0.0038428581319749355,
      "learning_rate": 3.869252613135158e-06,
      "loss": 0.07,
      "step": 13350
    },
    {
      "epoch": 2.4288562624614825,
      "grad_norm": 0.007975499145686626,
      "learning_rate": 3.8088333031236783e-06,
      "loss": 0.1091,
      "step": 13400
    },
    {
      "epoch": 2.4379191589632048,
      "grad_norm": 0.1069275289773941,
      "learning_rate": 3.7484139931121986e-06,
      "loss": 0.1624,
      "step": 13450
    },
    {
      "epoch": 2.4469820554649266,
      "grad_norm": 0.30813655257225037,
      "learning_rate": 3.687994683100719e-06,
      "loss": 0.2085,
      "step": 13500
    },
    {
      "epoch": 2.4560449519666485,
      "grad_norm": 0.27826637029647827,
      "learning_rate": 3.6275753730892393e-06,
      "loss": 0.091,
      "step": 13550
    },
    {
      "epoch": 2.4651078484683704,
      "grad_norm": 0.5499745607376099,
      "learning_rate": 3.56715606307776e-06,
      "loss": 0.0592,
      "step": 13600
    },
    {
      "epoch": 2.4741707449700923,
      "grad_norm": 0.049129802733659744,
      "learning_rate": 3.5067367530662804e-06,
      "loss": 0.1482,
      "step": 13650
    },
    {
      "epoch": 2.4832336414718146,
      "grad_norm": 0.10409585386514664,
      "learning_rate": 3.4463174430548007e-06,
      "loss": 0.0749,
      "step": 13700
    },
    {
      "epoch": 2.4922965379735365,
      "grad_norm": 0.011093678884208202,
      "learning_rate": 3.385898133043321e-06,
      "loss": 0.1171,
      "step": 13750
    },
    {
      "epoch": 2.5013594344752583,
      "grad_norm": 0.002829811302945018,
      "learning_rate": 3.3254788230318414e-06,
      "loss": 0.1188,
      "step": 13800
    },
    {
      "epoch": 2.51042233097698,
      "grad_norm": 0.0032032066956162453,
      "learning_rate": 3.2650595130203617e-06,
      "loss": 0.1008,
      "step": 13850
    },
    {
      "epoch": 2.519485227478702,
      "grad_norm": 71.45816040039062,
      "learning_rate": 3.204640203008882e-06,
      "loss": 0.1358,
      "step": 13900
    },
    {
      "epoch": 2.528548123980424,
      "grad_norm": 0.619956910610199,
      "learning_rate": 3.1442208929974023e-06,
      "loss": 0.137,
      "step": 13950
    },
    {
      "epoch": 2.537611020482146,
      "grad_norm": 8.722743034362793,
      "learning_rate": 3.0838015829859227e-06,
      "loss": 0.1464,
      "step": 14000
    },
    {
      "epoch": 2.546673916983868,
      "grad_norm": 115.70531463623047,
      "learning_rate": 3.0233822729744426e-06,
      "loss": 0.1485,
      "step": 14050
    },
    {
      "epoch": 2.55573681348559,
      "grad_norm": 0.1966806948184967,
      "learning_rate": 2.962962962962963e-06,
      "loss": 0.1318,
      "step": 14100
    },
    {
      "epoch": 2.564799709987312,
      "grad_norm": 0.07117088884115219,
      "learning_rate": 2.9025436529514832e-06,
      "loss": 0.0779,
      "step": 14150
    },
    {
      "epoch": 2.5738626064890338,
      "grad_norm": 0.02745247446000576,
      "learning_rate": 2.8421243429400036e-06,
      "loss": 0.1032,
      "step": 14200
    },
    {
      "epoch": 2.582925502990756,
      "grad_norm": 0.010948121547698975,
      "learning_rate": 2.7817050329285243e-06,
      "loss": 0.0639,
      "step": 14250
    },
    {
      "epoch": 2.591988399492478,
      "grad_norm": 0.04717062786221504,
      "learning_rate": 2.7212857229170446e-06,
      "loss": 0.1283,
      "step": 14300
    },
    {
      "epoch": 2.6010512959942,
      "grad_norm": 0.9225481152534485,
      "learning_rate": 2.660866412905565e-06,
      "loss": 0.1367,
      "step": 14350
    },
    {
      "epoch": 2.6101141924959217,
      "grad_norm": 0.5501325726509094,
      "learning_rate": 2.6004471028940853e-06,
      "loss": 0.1915,
      "step": 14400
    },
    {
      "epoch": 2.6191770889976436,
      "grad_norm": 0.0028019645251333714,
      "learning_rate": 2.5400277928826056e-06,
      "loss": 0.1225,
      "step": 14450
    },
    {
      "epoch": 2.6282399854993654,
      "grad_norm": 0.18296955525875092,
      "learning_rate": 2.479608482871126e-06,
      "loss": 0.1238,
      "step": 14500
    },
    {
      "epoch": 2.6373028820010873,
      "grad_norm": 0.10115118324756622,
      "learning_rate": 2.4191891728596463e-06,
      "loss": 0.0806,
      "step": 14550
    },
    {
      "epoch": 2.6463657785028096,
      "grad_norm": 0.006987254600971937,
      "learning_rate": 2.3587698628481666e-06,
      "loss": 0.1801,
      "step": 14600
    },
    {
      "epoch": 2.6554286750045315,
      "grad_norm": 0.19699697196483612,
      "learning_rate": 2.298350552836687e-06,
      "loss": 0.1222,
      "step": 14650
    },
    {
      "epoch": 2.6644915715062534,
      "grad_norm": 0.027995871379971504,
      "learning_rate": 2.237931242825207e-06,
      "loss": 0.1446,
      "step": 14700
    },
    {
      "epoch": 2.6735544680079752,
      "grad_norm": 0.08518888056278229,
      "learning_rate": 2.1775119328137276e-06,
      "loss": 0.0738,
      "step": 14750
    },
    {
      "epoch": 2.6826173645096976,
      "grad_norm": 0.006265251897275448,
      "learning_rate": 2.117092622802248e-06,
      "loss": 0.1518,
      "step": 14800
    },
    {
      "epoch": 2.6916802610114194,
      "grad_norm": 0.12268085032701492,
      "learning_rate": 2.0566733127907683e-06,
      "loss": 0.0875,
      "step": 14850
    },
    {
      "epoch": 2.7007431575131413,
      "grad_norm": 12.57502555847168,
      "learning_rate": 1.9962540027792886e-06,
      "loss": 0.135,
      "step": 14900
    },
    {
      "epoch": 2.709806054014863,
      "grad_norm": 0.096290722489357,
      "learning_rate": 1.935834692767809e-06,
      "loss": 0.1409,
      "step": 14950
    },
    {
      "epoch": 2.718868950516585,
      "grad_norm": 0.04574182629585266,
      "learning_rate": 1.875415382756329e-06,
      "loss": 0.0822,
      "step": 15000
    },
    {
      "epoch": 2.727931847018307,
      "grad_norm": 0.08440794050693512,
      "learning_rate": 1.8149960727448494e-06,
      "loss": 0.1463,
      "step": 15050
    },
    {
      "epoch": 2.736994743520029,
      "grad_norm": 43.0927734375,
      "learning_rate": 1.75457676273337e-06,
      "loss": 0.0649,
      "step": 15100
    },
    {
      "epoch": 2.7460576400217507,
      "grad_norm": 0.1629135012626648,
      "learning_rate": 1.6941574527218902e-06,
      "loss": 0.1153,
      "step": 15150
    },
    {
      "epoch": 2.755120536523473,
      "grad_norm": 0.0017576751997694373,
      "learning_rate": 1.6337381427104103e-06,
      "loss": 0.1291,
      "step": 15200
    },
    {
      "epoch": 2.764183433025195,
      "grad_norm": 131.83935546875,
      "learning_rate": 1.5733188326989307e-06,
      "loss": 0.138,
      "step": 15250
    },
    {
      "epoch": 2.7732463295269167,
      "grad_norm": 0.06091200187802315,
      "learning_rate": 1.512899522687451e-06,
      "loss": 0.1374,
      "step": 15300
    },
    {
      "epoch": 2.7823092260286386,
      "grad_norm": 31.489208221435547,
      "learning_rate": 1.4524802126759713e-06,
      "loss": 0.1479,
      "step": 15350
    },
    {
      "epoch": 2.791372122530361,
      "grad_norm": 64.51232147216797,
      "learning_rate": 1.3920609026644917e-06,
      "loss": 0.0901,
      "step": 15400
    },
    {
      "epoch": 2.800435019032083,
      "grad_norm": 0.5269655585289001,
      "learning_rate": 1.3316415926530122e-06,
      "loss": 0.1275,
      "step": 15450
    },
    {
      "epoch": 2.8094979155338047,
      "grad_norm": 0.07795492559671402,
      "learning_rate": 1.2712222826415323e-06,
      "loss": 0.0914,
      "step": 15500
    },
    {
      "epoch": 2.8185608120355266,
      "grad_norm": 0.14424602687358856,
      "learning_rate": 1.2108029726300526e-06,
      "loss": 0.1332,
      "step": 15550
    },
    {
      "epoch": 2.8276237085372484,
      "grad_norm": 0.057564008980989456,
      "learning_rate": 1.150383662618573e-06,
      "loss": 0.135,
      "step": 15600
    },
    {
      "epoch": 2.8366866050389703,
      "grad_norm": 31.60073471069336,
      "learning_rate": 1.0899643526070933e-06,
      "loss": 0.1747,
      "step": 15650
    },
    {
      "epoch": 2.845749501540692,
      "grad_norm": 30.987110137939453,
      "learning_rate": 1.0295450425956136e-06,
      "loss": 0.1573,
      "step": 15700
    },
    {
      "epoch": 2.8548123980424145,
      "grad_norm": 6.478113651275635,
      "learning_rate": 9.69125732584134e-07,
      "loss": 0.1377,
      "step": 15750
    },
    {
      "epoch": 2.8638752945441364,
      "grad_norm": 0.43592461943626404,
      "learning_rate": 9.087064225726543e-07,
      "loss": 0.0818,
      "step": 15800
    },
    {
      "epoch": 2.8729381910458582,
      "grad_norm": 18.315185546875,
      "learning_rate": 8.482871125611747e-07,
      "loss": 0.1068,
      "step": 15850
    },
    {
      "epoch": 2.88200108754758,
      "grad_norm": 0.007903937250375748,
      "learning_rate": 7.878678025496949e-07,
      "loss": 0.153,
      "step": 15900
    },
    {
      "epoch": 2.8910639840493024,
      "grad_norm": 10.832182884216309,
      "learning_rate": 7.274484925382153e-07,
      "loss": 0.0495,
      "step": 15950
    },
    {
      "epoch": 2.9001268805510243,
      "grad_norm": 0.012130923569202423,
      "learning_rate": 6.670291825267355e-07,
      "loss": 0.0847,
      "step": 16000
    },
    {
      "epoch": 2.909189777052746,
      "grad_norm": 7.982913970947266,
      "learning_rate": 6.066098725152559e-07,
      "loss": 0.103,
      "step": 16050
    },
    {
      "epoch": 2.918252673554468,
      "grad_norm": 0.2665311098098755,
      "learning_rate": 5.461905625037763e-07,
      "loss": 0.1573,
      "step": 16100
    },
    {
      "epoch": 2.92731557005619,
      "grad_norm": 0.10958138853311539,
      "learning_rate": 4.857712524922966e-07,
      "loss": 0.1404,
      "step": 16150
    },
    {
      "epoch": 2.936378466557912,
      "grad_norm": 0.03031168319284916,
      "learning_rate": 4.253519424808169e-07,
      "loss": 0.144,
      "step": 16200
    },
    {
      "epoch": 2.9454413630596337,
      "grad_norm": 0.20207898318767548,
      "learning_rate": 3.6493263246933724e-07,
      "loss": 0.1199,
      "step": 16250
    },
    {
      "epoch": 2.9545042595613555,
      "grad_norm": 0.049038879573345184,
      "learning_rate": 3.0451332245785757e-07,
      "loss": 0.1265,
      "step": 16300
    },
    {
      "epoch": 2.963567156063078,
      "grad_norm": 0.30882853269577026,
      "learning_rate": 2.440940124463779e-07,
      "loss": 0.1846,
      "step": 16350
    },
    {
      "epoch": 2.9726300525647997,
      "grad_norm": 0.07628358900547028,
      "learning_rate": 1.836747024348982e-07,
      "loss": 0.137,
      "step": 16400
    },
    {
      "epoch": 2.9816929490665216,
      "grad_norm": 0.2381208837032318,
      "learning_rate": 1.2325539242341853e-07,
      "loss": 0.1147,
      "step": 16450
    },
    {
      "epoch": 2.9907558455682435,
      "grad_norm": 0.08920780569314957,
      "learning_rate": 6.283608241193886e-08,
      "loss": 0.0822,
      "step": 16500
    },
    {
      "epoch": 2.999818742069966,
      "grad_norm": 0.9602258205413818,
      "learning_rate": 2.416772400459187e-09,
      "loss": 0.1865,
      "step": 16550
    },
    {
      "epoch": 3.0,
      "eval_acc_3class": 0.968932443703086,
      "eval_any_f1": 0.9403919983835117,
      "eval_any_precision": 0.9121912975303802,
      "eval_any_recall": 0.9703919933277732,
      "eval_cm00": 6970,
      "eval_cm01": 224,
      "eval_cm02": 0,
      "eval_cm10": 70,
      "eval_cm11": 1711,
      "eval_cm12": 0,
      "eval_cm20": 1,
      "eval_cm21": 3,
      "eval_cm22": 613,
      "eval_loss": 0.1319236159324646,
      "eval_runtime": 13.7364,
      "eval_samples_per_second": 698.289,
      "eval_steps_per_second": 43.679,
      "eval_type_f1": 0.9975589910496339,
      "eval_type_precision": 1.0,
      "eval_type_recall": 0.9951298701298701,
      "eval_type_support": 2327.0,
      "step": 16551
    },
    {
      "epoch": 3.0,
      "step": 16551,
      "total_flos": 1.0850702790718224e+16,
      "train_loss": 0.23004285631694935,
      "train_runtime": 1019.474,
      "train_samples_per_second": 129.879,
      "train_steps_per_second": 16.235
    }
  ],
  "logging_steps": 50,
  "max_steps": 16551,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.0850702790718224e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
